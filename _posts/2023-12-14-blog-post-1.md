---
title: 'Introduction to MapReduce'
date: 2023-12-20
permalink: /posts/2023/12/blog-post-1/
tags:
  - Distributed System
---

# MapReduce

# What is MapReduce?

- a programming model
- help process and generate large datasets
- it consists of 2 functions: map and reduce
  - map: take an input pair and produce a set of intermediate key/value pairs
  - reduce: take the intermediate keys and values as input and merges the values to form a possibly smaller set of values
  - map and reduce are written by the user

# Example

## words count

```jsx
map(String key, String value):
    // key: document name
    // value: document contents
    for each word w in value:
      EmitIntermediate(w, "1");

reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
      result += ParseInt(v);
    Emit(AsString(result));
```

The map function emits each word plus an associated count of occurrences (just ‘1’ in this simple example). The reduce function sums together all counts emitted for a particular word.

```jsx
Input1 -> Map -> a,1 b,1
  Input2 -> Map ->     b,1
  Input3 -> Map -> a,1     c,1
                    |   |   |
                    |   |   -> Reduce -> c,1
                    |   -----> Reduce -> b,2
                    ---------> Reduce -> a,2
```

1. input is (already) split into M files
2. MR calls Map() for each input file, produces list of k,v pairs
   "intermediate" data
   each Map() call is a "task"
3. when Maps are done,
   MR gathers all intermediate v's for each k,
   and passes each key + values to a Reduce call
4. final output is set of <k,v> pairs from Reduce()s

# Execution Overview

1. MapReduce library splits the input files and make copies of the program on a cluster of machines
2. One machine is special — master, others are workers. It assigns a map task or a reduce task to idle workers 
3. A worker who is assigned a map task reads the content of the corresponding input split and generate intermediate key/value pairs and buffer them in memory.
4. The buffered pairs are written to local disk periodically. The master knows the locations of the buffered pairs.
5. A worker who is assigned a reduce task gets information of the locations from the master by using  remote procedure calls, then it sorts the data by the intermediate keys so that all 1. occurrences of the same key are grouped together.
6. The reduce worker **iterates** **over** the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s Reduce function. The output is a file.
7. When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user pro- gram returns back to the user code.

After successful completion, the output of the MapReduce execution is available in the R output files (**one per reduce task**, with file names as specified by the user).

# Master Data Structures

- It stores the state (idle, in progress or completed) of a task and the identity of the worker machine
- It stores the locations and sizes of the R intermediate file regions produced by the map task.
